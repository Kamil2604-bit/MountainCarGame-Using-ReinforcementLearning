import gym
import numpy as np
import matplotlib.pyplot as plt
from moviepy.editor import ImageSequenceClip
import imageio

# Hyperparameters
alpha = 0.1  # Learning rate
gamma = 0.99  # Discount factor
epsilon = 1.0  # Exploration rate
epsilon_decay = 0.995
min_epsilon = 0.01
num_episodes = 5000

# Discretize the state space (optional, improves performance)
num_position_bins = 20
num_velocity_bins = 20

def discretize_state(state):
    position, velocity = state
    position_bin = int(position * num_position_bins)
    velocity_bin = int(velocity * num_velocity_bins)
    return position_bin, velocity_bin

# Initialize Q-table
env = gym.make("MountainCar-v0")
state_size = (num_position_bins, num_velocity_bins)
action_size = env.action_space.n
q_table = np.zeros(state_size + (action_size,))

# Training loop
rewards = []
for episode in range(num_episodes):
    state = env.reset()
    state = discretize_state(state)
    total_reward = 0
    done = False
    while not done:
        # Epsilon-greedy policy
        if np.random.rand() < epsilon:
            action = env.action_space.sample()
        else:
            action = np.argmax(q_table[state])

        next_state, reward, done, _ = env.step(action)
        next_state = discretize_state(next_state)

        # Q-learning update
        old_value = q_table[state + (action,)]
        next_max = np.max(q_table[next_state])
        new_value = (1 - alpha) * old_value + alpha * (reward + gamma * next_max)
        q_table[state + (action,)] = new_value

        state = next_state
        total_reward += reward

    rewards.append(total_reward)
    epsilon = max(epsilon * epsilon_decay, min_epsilon)
    if (episode + 1) % 100 == 0:
        print(f"Episode {episode + 1}, Total Reward: {total_reward}, Epsilon: {epsilon}")

# Plotting the rewards
plt.plot(rewards)
plt.xlabel("Episode")
plt.ylabel("Total Reward")
plt.title("MountainCar Training Rewards")
plt.show()

# Testing and video recording
frames = []
state = env.reset()
state = discretize_state(state)
done = False
while not done:
    action = np.argmax(q_table[state])
    state, reward, done, _ = env.step(action)
    frames.append(env.render(mode='rgb_array'))
    state = discretize_state(state)

env.close()


clip = ImageSequenceClip(frames, fps=30)
clip.write_gif("mountaincar_solution.gif", fps=30) #or use .mp4 for video

#Displaying the GIF (only works in a Jupyter Notebook or similar environment)
from IPython.display import Image
Image(url='mountaincar_solution.gif')
